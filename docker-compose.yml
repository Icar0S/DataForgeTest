services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: dataforgetest-backend
    ports:
      - "5000:5000"
    environment:
      # Flask Settings
      - FLASK_ENV=production
      - FLASK_DEBUG=False
      
      # LLM Configuration (Anthropic Claude)
      # Set your API key via environment variable or .env file
      - LLM_API_KEY=${LLM_API_KEY:-}
      - LLM_MODEL=${LLM_MODEL:-claude-3-haiku-20240307}
      
      # RAG System
      - VECTOR_STORE_PATH=./storage/vectorstore
      - CHUNK_SIZE=${CHUNK_SIZE:-512}
      - CHUNK_OVERLAP=${CHUNK_OVERLAP:-50}
      - TOP_K=${TOP_K:-4}
      - MAX_UPLOAD_MB=${MAX_UPLOAD_MB:-10}
      
      # Synthetic Data Generation
      - SYNTH_STORAGE_PATH=./storage/synth
      - SYNTH_MAX_ROWS=${SYNTH_MAX_ROWS:-1000000}
      - SYNTH_REQUEST_TIMEOUT=${SYNTH_REQUEST_TIMEOUT:-300}
      - SYNTH_MAX_MEM_MB=${SYNTH_MAX_MEM_MB:-2048}
      
      # Data Accuracy
      - ACCURACY_STORAGE_PATH=./storage/accuracy
      - ACCURACY_MAX_UPLOAD_MB=${ACCURACY_MAX_UPLOAD_MB:-50}
      - ACCURACY_MAX_ROWS=${ACCURACY_MAX_ROWS:-2000000}
      - ACCURACY_REQUEST_TIMEOUT=${ACCURACY_REQUEST_TIMEOUT:-120}
      
      # GOLD Dataset Testing
      - GOLD_STORAGE_PATH=./storage/gold
      - GOLD_ALLOWED_FILE_TYPES=${GOLD_ALLOWED_FILE_TYPES:-.csv,.xlsx,.xls,.parquet}
      - MAX_ROWS_WARN=${MAX_ROWS_WARN:-500000}
      - GOLD_REQUEST_TIMEOUT=${GOLD_REQUEST_TIMEOUT:-300}
    volumes:
      # Persist storage data
      - ./storage:/app/storage
      # Persist uploaded files
      - ./uploads:/app/uploads
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:5000/', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  storage:
  uploads:
